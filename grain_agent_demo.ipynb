{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ğŸ§ª ì—ì´ì „íŠ¸ í†µí•© ë°ëª¨ (rules_core ì—°ë™, ipynb)\n",
    "\n",
    "**ëª©í‘œ**: ê¸°ì¡´ **ë£°ë² ì´ìŠ¤ ì¶”ì²œê¸°(`rules_core.py`)** ìœ„ì— **ì—ì´ì „íŠ¸ ë ˆì´ì–´**ë¥¼ ì–¹ì–´,\n",
    "ì˜ì‚¬(ì‹œë®¬ë ˆì´ì…˜) í”¼ë“œë°± â†’ ë­ì»¤ í•™ìŠµ â†’ ì¶”ë¡ (ë£° ê·¼ë°© ë¦¬ë­í‚¹)ì„ í•œ ë²ˆì— í™•ì¸í•©ë‹ˆë‹¤.\n",
    "\n",
    "**ì‚¬ì „ ì¤€ë¹„**\n",
    "- í”„ë¡œì íŠ¸ ë£¨íŠ¸ì— ì•„ë˜ íŒŒì¼ì´ ìˆì–´ì•¼ í•©ë‹ˆë‹¤.\n",
    "  - `rules_core.py`  â† ì—¬ëŸ¬ë¶„ì˜ ê¸°ì¡´ ë£° ì½”ë“œ(ì„¤ë¬¸â†’ì ìˆ˜â†’ë°°í•©)\n",
    "  - `agent_core.py`  â† ì—ì´ì „íŠ¸ í•µì‹¬(ë³´ìƒ/í”¼ì²˜/ë°ì´í„°ì…‹/ë­ì»¤)\n",
    "  - `agent_adapter.py` â† ë£°â†”ì—ì´ì „íŠ¸ ì—°ê²°(ì„¤ë¬¸â†’Context, ë£° í›…)\n",
    "- íŒŒì´ì¬ íŒ¨í‚¤ì§€: `scikit-learn` (ì—†ë‹¤ë©´ ì•„ë˜ ì„¤ì¹˜ ì…€ ì°¸ê³ )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: scikit-learn in c:\\users\\hslee\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (1.7.2)\n",
      "Requirement already satisfied: ipywidgets in c:\\users\\hslee\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (8.1.7)\n",
      "Requirement already satisfied: numpy>=1.22.0 in c:\\users\\hslee\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from scikit-learn) (2.3.3)\n",
      "Requirement already satisfied: scipy>=1.8.0 in c:\\users\\hslee\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from scikit-learn) (1.16.2)\n",
      "Requirement already satisfied: joblib>=1.2.0 in c:\\users\\hslee\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from scikit-learn) (1.5.2)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in c:\\users\\hslee\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from scikit-learn) (3.6.0)\n",
      "Requirement already satisfied: comm>=0.1.3 in c:\\users\\hslee\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from ipywidgets) (0.2.3)\n",
      "Requirement already satisfied: ipython>=6.1.0 in c:\\users\\hslee\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from ipywidgets) (9.5.0)\n",
      "Requirement already satisfied: traitlets>=4.3.1 in c:\\users\\hslee\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from ipywidgets) (5.14.3)\n",
      "Requirement already satisfied: widgetsnbextension~=4.0.14 in c:\\users\\hslee\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from ipywidgets) (4.0.14)\n",
      "Requirement already satisfied: jupyterlab_widgets~=3.0.15 in c:\\users\\hslee\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from ipywidgets) (3.0.15)\n",
      "Requirement already satisfied: colorama in c:\\users\\hslee\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from ipython>=6.1.0->ipywidgets) (0.4.6)\n",
      "Requirement already satisfied: decorator in c:\\users\\hslee\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from ipython>=6.1.0->ipywidgets) (5.2.1)\n",
      "Requirement already satisfied: ipython-pygments-lexers in c:\\users\\hslee\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from ipython>=6.1.0->ipywidgets) (1.1.1)\n",
      "Requirement already satisfied: jedi>=0.16 in c:\\users\\hslee\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from ipython>=6.1.0->ipywidgets) (0.19.2)\n",
      "Requirement already satisfied: matplotlib-inline in c:\\users\\hslee\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from ipython>=6.1.0->ipywidgets) (0.1.7)\n",
      "Requirement already satisfied: prompt_toolkit<3.1.0,>=3.0.41 in c:\\users\\hslee\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from ipython>=6.1.0->ipywidgets) (3.0.52)\n",
      "Requirement already satisfied: pygments>=2.4.0 in c:\\users\\hslee\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from ipython>=6.1.0->ipywidgets) (2.19.2)\n",
      "Requirement already satisfied: stack_data in c:\\users\\hslee\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from ipython>=6.1.0->ipywidgets) (0.6.3)\n",
      "Requirement already satisfied: wcwidth in c:\\users\\hslee\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from prompt_toolkit<3.1.0,>=3.0.41->ipython>=6.1.0->ipywidgets) (0.2.13)\n",
      "Requirement already satisfied: parso<0.9.0,>=0.8.4 in c:\\users\\hslee\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from jedi>=0.16->ipython>=6.1.0->ipywidgets) (0.8.5)\n",
      "Requirement already satisfied: executing>=1.2.0 in c:\\users\\hslee\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from stack_data->ipython>=6.1.0->ipywidgets) (2.2.1)\n",
      "Requirement already satisfied: asttokens>=2.1.0 in c:\\users\\hslee\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from stack_data->ipython>=6.1.0->ipywidgets) (3.0.0)\n",
      "Requirement already satisfied: pure-eval in c:\\users\\hslee\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from stack_data->ipython>=6.1.0->ipywidgets) (0.2.3)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "# (ì„ íƒ) ì„¤ì¹˜ â€” í™˜ê²½ì— ë”°ë¼ í•„ìš”í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.\n",
    "%pip install scikit-learn ipywidgets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1) ëª¨ë“ˆ ì„í¬íŠ¸ & í™˜ê²½ ì ê²€"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ” rules_core / agent_core / agent_adapter import OK\n",
      "GRAINS shape: (16, 9)\n",
      "WEIGHTS keys (sample): ['base_rules', 'purpose', 'texture_taste', 'constitution_gut', 'frequency', 'allergen', 'caps', 'mins']\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ê³¡ë¬¼</th>\n",
       "      <th>íƒœê·¸</th>\n",
       "      <th>ì„¬ìœ </th>\n",
       "      <th>ë‹¨ë°±</th>\n",
       "      <th>ë¶€ë“œëŸ¬ì›€</th>\n",
       "      <th>ì«€ë“</th>\n",
       "      <th>ê³ ì†Œ</th>\n",
       "      <th>GI</th>\n",
       "      <th>ê¸€ë£¨í…</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ë°±ë¯¸</td>\n",
       "      <td>[base, soft, mild]</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>í˜„ë¯¸</td>\n",
       "      <td>[base, chewy, nutty]</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ì°¹ìŒ€</td>\n",
       "      <td>[base, soft, sticky]</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ë³´ë¦¬</td>\n",
       "      <td>[base, fiber, chewy]</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ê·€ë¦¬</td>\n",
       "      <td>[fiber, nutty]</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   ê³¡ë¬¼                    íƒœê·¸  ì„¬ìœ   ë‹¨ë°±  ë¶€ë“œëŸ¬ì›€  ì«€ë“  ê³ ì†Œ  GI  ê¸€ë£¨í…\n",
       "0  ë°±ë¯¸    [base, soft, mild]   0   0     3   0   0   3    0\n",
       "1  í˜„ë¯¸  [base, chewy, nutty]   2   1     1   2   1   2    0\n",
       "2  ì°¹ìŒ€  [base, soft, sticky]   0   0     3   0   0   3    0\n",
       "3  ë³´ë¦¬  [base, fiber, chewy]   3   1     1   2   1   1    1\n",
       "4  ê·€ë¦¬        [fiber, nutty]   3   2     1   1   2   2    0"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ğŸ”§ ëª¨ë“ˆ ë¡œë“œ\n",
    "from importlib import import_module\n",
    "\n",
    "try:\n",
    "    rules_core = import_module('rules_core')\n",
    "except Exception as e:\n",
    "    raise RuntimeError(\"rules_core.py(ì—¬ëŸ¬ë¶„ì˜ ë£° ì½”ë“œ)ë¥¼ í”„ë¡œì íŠ¸ ë£¨íŠ¸ì— ë‘ê³  ë‹¤ì‹œ ì‹¤í–‰í•˜ì„¸ìš”.\") from e\n",
    "\n",
    "try:\n",
    "    agent_core   = import_module('agent_core')\n",
    "    agent_adapter = import_module('agent_adapter')\n",
    "except Exception as e:\n",
    "    raise RuntimeError(\"agent_core.py / agent_adapter.py ê°€ ëˆ„ë½ë˜ì—ˆìŠµë‹ˆë‹¤. í”„ë¡œì íŠ¸ ë£¨íŠ¸ì— ì €ì¥í•´ ì£¼ì„¸ìš”.\") from e\n",
    "\n",
    "assert hasattr(rules_core, 'GRAINS')\n",
    "assert hasattr(rules_core, 'WEIGHTS')\n",
    "assert hasattr(rules_core, 'generate_candidates')\n",
    "\n",
    "print(\"âœ” rules_core / agent_core / agent_adapter import OK\")\n",
    "print(\"GRAINS shape:\", getattr(rules_core.GRAINS, 'shape', None))\n",
    "print(\"WEIGHTS keys (sample):\", list(rules_core.WEIGHTS.keys())[:8])\n",
    "\n",
    "# ì¹´íƒˆë¡œê·¸ ë¯¸ë¦¬ë³´ê¸°(ì„ íƒ)\n",
    "rules_core.GRAINS.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2) ì„¤ë¬¸ ê°’ê³µê°„ ì „ìˆ˜ + í­ ì œí•œ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "67a00058",
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "\n",
    "def _powerset_limited(opts, k_max):\n",
    "    out = [tuple()]  # ê³µì§‘í•©\n",
    "    for k in range(1, k_max+1):\n",
    "        out.extend(itertools.combinations(opts, k))\n",
    "    return out\n",
    "\n",
    "def build_value_space_from_schema_exhaustive(schema: dict, grains_df, multiselect_mode='powerset_k', k_max=2):\n",
    "    \"\"\"\n",
    "    ìŠ¤í‚¤ë§ˆ ê¸°ë°˜ ì „ìˆ˜ìš© ê°’ê³µê°„ ìƒì„±.\n",
    "    - dropdown: options ì „ë¶€\n",
    "    - int: min..max..step\n",
    "    - checkbox: [False, True]\n",
    "    - multiselect(grains): 'ì—†ìŒ' + (ê³¡ë¬¼ì—ì„œ 0~k_maxê°œ ì¡°í•©)  â† í­ ì œí•œ\n",
    "    ë°˜í™˜: dict[name] = list-of-values (ë©€í‹°ì…€ë ‰íŠ¸ëŠ” listë¡œ)\n",
    "    \"\"\"\n",
    "    grains = sorted(grains_df[\"ê³¡ë¬¼\"].astype(str).tolist())\n",
    "    space = {}\n",
    "    for sec in schema.get(\"sections\", []):\n",
    "        t, name = sec.get(\"type\"), sec.get(\"name\")\n",
    "        if not t or not name:\n",
    "            continue\n",
    "\n",
    "        if t == \"dropdown\":\n",
    "            space[name] = list(sec.get(\"options\", []))\n",
    "\n",
    "        elif t == \"int\":\n",
    "            vmin, vmax, step = int(sec.get(\"min\", 0)), int(sec.get(\"max\", 10)), int(sec.get(\"step\", 1))\n",
    "            space[name] = list(range(vmin, vmax+1, step))\n",
    "\n",
    "        elif t == \"checkbox\":\n",
    "            space[name] = [False, True]\n",
    "\n",
    "        elif t == \"multiselect\":\n",
    "            if sec.get(\"options_from\") == \"grains\":\n",
    "                base = [g for g in grains]  # ê³¡ë¬¼ ì „ì²´\n",
    "            else:\n",
    "                base = list(sec.get(\"options\", []))\n",
    "            # ì „ìˆ˜ í­ì„ ì¤„ì´ê¸° ìœ„í•´: 'ì—†ìŒ' + 0~kê°œ ì¡°í•©\n",
    "            if multiselect_mode == 'powerset_k':\n",
    "                tuples = _powerset_limited(base, k_max)  # () , (a), (a,b) ...\n",
    "                lists  = [list(t) for t in tuples]\n",
    "                space[name] = [[\"ì—†ìŒ\"]] + [lst for lst in lists if lst]  # ê³µì§‘í•© ëŒ€ì‹  'ì—†ìŒ' ì‚¬ìš©\n",
    "            else:\n",
    "                # ë‹¨ì¼ì„ íƒë§Œ(í­ ë” ì¤„ì´ê¸°)\n",
    "                space[name] = [[\"ì—†ìŒ\"]] + [[g] for g in base]\n",
    "\n",
    "    # í•˜ìœ„ í˜¸í™˜ í•„ë“œ(ìŠ¤í‚¤ë§ˆì— ì—†ìœ¼ë©´ ê¸°ë³¸ í›„ë³´ 1ê°œ)\n",
    "    for k, v in [(\"ì²´ì§ˆ\", [\"ë³´í†µ\"]), (\"ì¥ê±´ê°•\", [\"ë³´í†µ\"]), (\"ë§›\", [\"ë‹´ë°±/ì¤‘ì„±\"])]:\n",
    "        space.setdefault(k, v)\n",
    "\n",
    "    return space\n",
    "\n",
    "def estimate_combinations(space: dict) -> int:\n",
    "    n = 1\n",
    "    for v in space.values():\n",
    "        n *= max(1, len(v))\n",
    "    return n\n",
    "\n",
    "def iter_all_surveys(space: dict):\n",
    "    \"\"\"\n",
    "    ì „ìˆ˜ ì¡°í•©ì„ í•˜ë‚˜ì”© yield (ë©”ëª¨ë¦¬ ì•ˆì „)\n",
    "    ë©€í‹°ì…€ë ‰íŠ¸ ê°’ì€ ì´ë¯¸ list í˜•íƒœì—¬ì•¼ í•¨.\n",
    "    \"\"\"\n",
    "    keys = list(space.keys())\n",
    "    vals = [space[k] for k in keys]\n",
    "    for tpl in itertools.product(*vals):\n",
    "        s = dict(zip(keys, tpl))\n",
    "        # ì•ˆì „ ë³´ê°•(ê·œì¹™ì—ì„œ ì“°ëŠ” ê¸°ë³¸ê°’)\n",
    "        s.setdefault(\"ì²´ì§ˆ\", \"ë³´í†µ\")\n",
    "        s.setdefault(\"ì¥ê±´ê°•\", \"ë³´í†µ\")\n",
    "        s.setdefault(\"ë§›\", \"ë‹´ë°±/ì¤‘ì„±\")\n",
    "        # 'ì—†ìŒ' â†’ ì‹¤ì œ ë¬´ì„ íƒ\n",
    "        if isinstance(s.get(\"ê¸°í”¼ê³¡ë¬¼\"), list) and s[\"ê¸°í”¼ê³¡ë¬¼\"] == [\"ì—†ìŒ\"]:\n",
    "            s[\"ê¸°í”¼ê³¡ë¬¼\"] = [\"ì—†ìŒ\"]  # ì—¬ëŸ¬ë¶„ ê·œì¹™ì´ \"ì—†ìŒ\" ë¬¸ìì—´ì„ ê¸°ëŒ€í•˜ë¯€ë¡œ ê·¸ëŒ€ë¡œ ë‘ \n",
    "        yield s\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "57ea6567",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ì˜ˆìƒ ì „ìˆ˜ ê°œìˆ˜: 1420416\n",
      "ì§„í–‰: 10000\n",
      "ì§„í–‰: 20000\n",
      "ì§„í–‰: 30000\n",
      "ì§„í–‰: 40000\n",
      "ì§„í–‰: 50000\n",
      "ì§„í–‰: 60000\n",
      "ì§„í–‰: 70000\n",
      "ì§„í–‰: 80000\n",
      "ì§„í–‰: 90000\n",
      "ì§„í–‰: 100000\n",
      "ì§„í–‰: 110000\n",
      "ì§„í–‰: 120000\n",
      "ì§„í–‰: 130000\n",
      "ì§„í–‰: 140000\n",
      "ì§„í–‰: 150000\n",
      "ì§„í–‰: 160000\n",
      "ì§„í–‰: 170000\n",
      "ì§„í–‰: 180000\n",
      "ì§„í–‰: 190000\n",
      "ì§„í–‰: 200000\n",
      "ì§„í–‰: 210000\n",
      "ì§„í–‰: 220000\n",
      "ì§„í–‰: 230000\n",
      "ì§„í–‰: 240000\n",
      "ì§„í–‰: 250000\n",
      "ì§„í–‰: 260000\n",
      "ì§„í–‰: 270000\n",
      "ì§„í–‰: 280000\n",
      "ì§„í–‰: 290000\n",
      "ì§„í–‰: 300000\n",
      "ì§„í–‰: 310000\n",
      "ì§„í–‰: 320000\n",
      "ì§„í–‰: 330000\n",
      "ì§„í–‰: 340000\n",
      "ì§„í–‰: 350000\n",
      "ì§„í–‰: 360000\n",
      "ì§„í–‰: 370000\n",
      "ì§„í–‰: 380000\n",
      "ì§„í–‰: 390000\n",
      "ì§„í–‰: 400000\n",
      "ì§„í–‰: 410000\n",
      "ì§„í–‰: 420000\n",
      "ì§„í–‰: 430000\n",
      "ì§„í–‰: 440000\n",
      "ì§„í–‰: 450000\n",
      "ì§„í–‰: 460000\n",
      "ì§„í–‰: 470000\n",
      "ì§„í–‰: 480000\n",
      "ì§„í–‰: 490000\n",
      "ì§„í–‰: 500000\n",
      "ì§„í–‰: 510000\n",
      "ì§„í–‰: 520000\n",
      "ì§„í–‰: 530000\n",
      "ì§„í–‰: 540000\n",
      "ì§„í–‰: 550000\n",
      "ì§„í–‰: 560000\n",
      "ì§„í–‰: 570000\n",
      "ì§„í–‰: 580000\n",
      "ì§„í–‰: 590000\n",
      "ì§„í–‰: 600000\n",
      "ì§„í–‰: 610000\n",
      "ì§„í–‰: 620000\n",
      "ì§„í–‰: 630000\n",
      "ì§„í–‰: 640000\n",
      "ì§„í–‰: 650000\n",
      "ì§„í–‰: 660000\n",
      "ì§„í–‰: 670000\n",
      "ì§„í–‰: 680000\n",
      "ì§„í–‰: 690000\n",
      "ì§„í–‰: 700000\n",
      "ì§„í–‰: 710000\n",
      "ì§„í–‰: 720000\n",
      "ì§„í–‰: 730000\n",
      "ì§„í–‰: 740000\n",
      "ì§„í–‰: 750000\n",
      "ì§„í–‰: 760000\n",
      "ì§„í–‰: 770000\n",
      "ì§„í–‰: 780000\n",
      "ì§„í–‰: 790000\n",
      "ì§„í–‰: 800000\n",
      "ì§„í–‰: 810000\n",
      "ì§„í–‰: 820000\n",
      "ì§„í–‰: 830000\n",
      "ì§„í–‰: 840000\n",
      "ì§„í–‰: 850000\n",
      "ì§„í–‰: 860000\n",
      "ì§„í–‰: 870000\n",
      "ì§„í–‰: 880000\n",
      "ì§„í–‰: 890000\n",
      "ì§„í–‰: 900000\n",
      "ì§„í–‰: 910000\n",
      "ì§„í–‰: 920000\n",
      "ì§„í–‰: 930000\n",
      "ì§„í–‰: 940000\n",
      "ì§„í–‰: 950000\n",
      "ì§„í–‰: 960000\n",
      "ì§„í–‰: 970000\n",
      "ì§„í–‰: 980000\n",
      "ì§„í–‰: 990000\n",
      "ì§„í–‰: 1000000\n",
      "ì§„í–‰: 1010000\n",
      "ì§„í–‰: 1020000\n",
      "ì§„í–‰: 1030000\n",
      "ì§„í–‰: 1040000\n",
      "ì§„í–‰: 1050000\n",
      "ì§„í–‰: 1060000\n",
      "ì§„í–‰: 1070000\n",
      "ì§„í–‰: 1080000\n",
      "ì§„í–‰: 1090000\n",
      "ì§„í–‰: 1100000\n",
      "ì§„í–‰: 1110000\n",
      "ì§„í–‰: 1120000\n",
      "ì§„í–‰: 1130000\n",
      "ì§„í–‰: 1140000\n",
      "ì§„í–‰: 1150000\n",
      "ì§„í–‰: 1160000\n",
      "ì§„í–‰: 1170000\n",
      "ì§„í–‰: 1180000\n",
      "ì§„í–‰: 1190000\n",
      "ì§„í–‰: 1200000\n",
      "ì§„í–‰: 1210000\n",
      "ì§„í–‰: 1220000\n",
      "ì§„í–‰: 1230000\n",
      "ì§„í–‰: 1240000\n",
      "ì§„í–‰: 1250000\n",
      "ì§„í–‰: 1260000\n",
      "ì§„í–‰: 1270000\n",
      "ì§„í–‰: 1280000\n",
      "ì§„í–‰: 1290000\n",
      "ì§„í–‰: 1300000\n",
      "ì§„í–‰: 1310000\n",
      "ì§„í–‰: 1320000\n",
      "ì§„í–‰: 1330000\n",
      "ì§„í–‰: 1340000\n",
      "ì§„í–‰: 1350000\n",
      "ì§„í–‰: 1360000\n",
      "ì§„í–‰: 1370000\n",
      "ì§„í–‰: 1380000\n",
      "ì§„í–‰: 1390000\n",
      "ì§„í–‰: 1400000\n",
      "ì§„í–‰: 1410000\n",
      "ì§„í–‰: 1420000\n",
      "ì´ ì „ìˆ˜: 1420416\n",
      "{'ì·¨ì‹ ëª©ì ': 'í˜ˆë‹¹ê´€ë¦¬', 'í˜„ì¬ ê±´ê°• ì´ìŠˆ': 'ì—†ìŒ', 'ë‚˜ì´': 'ë¯¸ì„±ë…„í¬í•¨', 'ì„±ë³„': 'ë‚¨', 'ì„ í˜¸ì‹ê°/ë§›': 'ê³ ìŠ¬ë°¥', 'ì„­ì·¨ ë¹ˆë„': 'ë§¤ì¼', 'ê³¡ë¬¼ ìˆ˜': 5, 'ê¸°í”¼ê³¡ë¬¼': ['ì—†ìŒ'], 'ì•Œë ˆë¥´ê² íšŒí”¼(ê¸€ë£¨í…)': False, 'ì²´ì§ˆ': 'ë³´í†µ', 'ì¥ê±´ê°•': 'ë³´í†µ', 'ë§›': 'ë‹´ë°±/ì¤‘ì„±'}\n"
     ]
    }
   ],
   "source": [
    "# === ê°’ê³µê°„ ìœ í‹¸ ===\n",
    "import itertools\n",
    "\n",
    "def _powerset_limited(opts, k_max):\n",
    "    out = [tuple()]  # ê³µì§‘í•©\n",
    "    for k in range(1, k_max+1):\n",
    "        out.extend(itertools.combinations(opts, k))\n",
    "    return out\n",
    "\n",
    "def build_value_space_from_schema_exhaustive(schema: dict, grains_df, multiselect_mode='powerset_k', k_max=2):\n",
    "    grains = sorted(grains_df[\"ê³¡ë¬¼\"].astype(str).tolist())\n",
    "    space = {}\n",
    "    for sec in schema.get(\"sections\", []):\n",
    "        t, name = sec.get(\"type\"), sec.get(\"name\")\n",
    "        if not t or not name:\n",
    "            continue\n",
    "\n",
    "        if t == \"dropdown\":\n",
    "            space[name] = list(sec.get(\"options\", []))\n",
    "        elif t == \"int\":\n",
    "            vmin, vmax, step = int(sec.get(\"min\", 0)), int(sec.get(\"max\", 10)), int(sec.get(\"step\", 1))\n",
    "            space[name] = list(range(vmin, vmax+1, step))\n",
    "        elif t == \"checkbox\":\n",
    "            space[name] = [False, True]\n",
    "        elif t == \"multiselect\":\n",
    "            if sec.get(\"options_from\") == \"grains\":\n",
    "                base = [g for g in grains]\n",
    "            else:\n",
    "                base = list(sec.get(\"options\", []))\n",
    "            if multiselect_mode == 'powerset_k':\n",
    "                tuples = _powerset_limited(base, k_max)\n",
    "                lists  = [list(t) for t in tuples]\n",
    "                space[name] = [[\"ì—†ìŒ\"]] + [lst for lst in lists if lst]  # ê³µì§‘í•© ëŒ€ì‹  'ì—†ìŒ'\n",
    "            else:\n",
    "                space[name] = [[\"ì—†ìŒ\"]] + [[g] for g in base]\n",
    "\n",
    "    for k, v in [(\"ì²´ì§ˆ\", [\"ë³´í†µ\"]), (\"ì¥ê±´ê°•\", [\"ë³´í†µ\"]), (\"ë§›\", [\"ë‹´ë°±/ì¤‘ì„±\"])]:\n",
    "        space.setdefault(k, v)\n",
    "    return space\n",
    "\n",
    "def estimate_combinations(space: dict) -> int:\n",
    "    n = 1\n",
    "    for v in space.values():\n",
    "        n *= max(1, len(v))\n",
    "    return n\n",
    "\n",
    "def iter_all_surveys(space: dict):\n",
    "    keys = list(space.keys())\n",
    "    vals = [space[k] for k in keys]\n",
    "    for tpl in itertools.product(*vals):\n",
    "        s = dict(zip(keys, tpl))\n",
    "        s.setdefault(\"ì²´ì§ˆ\", \"ë³´í†µ\")\n",
    "        s.setdefault(\"ì¥ê±´ê°•\", \"ë³´í†µ\")\n",
    "        s.setdefault(\"ë§›\", \"ë‹´ë°±/ì¤‘ì„±\")\n",
    "        if isinstance(s.get(\"ê¸°í”¼ê³¡ë¬¼\"), list) and s[\"ê¸°í”¼ê³¡ë¬¼\"] == [\"ì—†ìŒ\"]:\n",
    "            s[\"ê¸°í”¼ê³¡ë¬¼\"] = [\"ì—†ìŒ\"]\n",
    "        yield s\n",
    "\n",
    "# === ê°’ê³µê°„ êµ¬ì„± & ì „ìˆ˜ ===\n",
    "space = build_value_space_from_schema_exhaustive(\n",
    "    rules_core.SURVEY_SCHEMA,\n",
    "    rules_core.GRAINS,\n",
    "    multiselect_mode='powerset_k',\n",
    "    k_max=2\n",
    ")\n",
    "\n",
    "# ì „ìˆ˜ í­ ì¤„ì´ê¸°: ê³¡ë¬¼ ìˆ˜ ê³ ì •\n",
    "space[\"ê³¡ë¬¼ ìˆ˜\"] = [5]\n",
    "\n",
    "print(\"ì˜ˆìƒ ì „ìˆ˜ ê°œìˆ˜:\", estimate_combinations(space))\n",
    "\n",
    "surveys_all = []\n",
    "for i, s in enumerate(iter_all_surveys(space), 1):\n",
    "    surveys_all.append(s)\n",
    "    if i % 10000 == 0:\n",
    "        print(\"ì§„í–‰:\", i)\n",
    "print(\"ì´ ì „ìˆ˜:\", len(surveys_all))\n",
    "print(surveys_all[0])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b57fe526",
   "metadata": {},
   "source": [
    "## 3) ì¸µí™” ìƒ˜í”Œë§ (í•™ìŠµ í‘œë³¸ ê· í˜•)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "6161cb97",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "subset í¬ê¸°: 60000\n",
      "ë¶„í¬: Counter({'ì²´ì¤‘ ê´€ë¦¬': 10000, 'ë§›ì¤‘ì‹¬': 10000, 'ì‹¬í˜ˆê´€ ê±´ê°•': 10000, 'í˜ˆë‹¹ê´€ë¦¬': 10000, 'ì¥ ê±´ê°•': 10000, 'ê·¼ìœ¡ ë° ì—ë„ˆì§€ ë³´ê°•': 10000})\n"
     ]
    }
   ],
   "source": [
    "from collections import defaultdict, Counter\n",
    "import random\n",
    "\n",
    "def stratified_sample_from_surveys(surveys, key: str, per_class: int = 800, seed: int = 42):\n",
    "    random.seed(seed)\n",
    "    buckets = defaultdict(list)\n",
    "    for s in surveys:\n",
    "        cls = s.get(key)\n",
    "        buckets[cls].append(s)\n",
    "        if len(buckets[cls]) > per_class * 3:\n",
    "            buckets[cls] = random.sample(buckets[cls], per_class * 2)\n",
    "\n",
    "    out = []\n",
    "    for cls, items in buckets.items():\n",
    "        if len(items) <= per_class:\n",
    "            out.extend(items)\n",
    "        else:\n",
    "            out.extend(random.sample(items, per_class))\n",
    "    random.shuffle(out)\n",
    "    return out\n",
    "\n",
    "# ğŸ‘‡ í•„ìš”ì— ë”°ë¼ per_class ì¡°ì ˆ (ê³¼í•˜ë©´ ì‹œê°„ì´ ì˜¤ë˜ ê±¸ë¦½ë‹ˆë‹¤)\n",
    "subset = stratified_sample_from_surveys(surveys_all, key=\"ì·¨ì‹ ëª©ì \", per_class=10000, seed=7)\n",
    "print(\"subset í¬ê¸°:\", len(subset))\n",
    "print(\"ë¶„í¬:\", Counter([s[\"ì·¨ì‹ ëª©ì \"] for s in subset]))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f0e17a4",
   "metadata": {},
   "source": [
    "## 4) âš ï¸ ë³´ìƒí•¨ìˆ˜ íŒ¨ì¹˜ (ë°°í•© ì˜ì¡´í˜• + reward ë°˜í™˜)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "131e077b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "agent_core.compute_metrics -> unified_compute_metrics\n",
      "agent_core.reward -> unified_reward\n"
     ]
    }
   ],
   "source": [
    "# === ë¯¹ìŠ¤ ì˜ì¡´í˜• compute_metrics (ë…¸íŠ¸ë¶ì—ì„œ ì„ì‹œ íŒ¨ì¹˜) ===\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "FEATURE_MAP = {\n",
    "    \"gi\": \"GI\",          # ì˜ˆ: GI (ë‚®ì„ìˆ˜ë¡ ì¢‹ìŒ)\n",
    "    \"fiber\": \"ì„¬ìœ \",      # ì˜ˆ: ì„¬ìœ \n",
    "    \"protein\": \"ë‹¨ë°±\",    # ì˜ˆ: ë‹¨ë°±ì§ˆ\n",
    "    \"soft\": \"ë¶€ë“œëŸ¬ì›€\",\n",
    "    \"sticky\": \"ì«€ë“\",\n",
    "    \"nutty\": \"ê³ ì†Œ\",\n",
    "    \"gluten\": \"ê¸€ë£¨í…\",   # 1/0 ë˜ëŠ” True/False\n",
    "}\n",
    "\n",
    "def _col(df, key, default=0.0):\n",
    "    col = FEATURE_MAP.get(key, key)\n",
    "    return df[col].astype(float).values if col in df.columns else np.full(len(df), default, float)\n",
    "\n",
    "def _mix_vector(mix, grains_df):\n",
    "    index = grains_df[\"ê³¡ë¬¼\"].astype(str).tolist()\n",
    "    vec = np.zeros(len(index), float)\n",
    "    for g, pct in (mix or {}).items():\n",
    "        try:\n",
    "            i = index.index(str(g))\n",
    "            vec[i] = float(pct)\n",
    "        except ValueError:\n",
    "            pass\n",
    "    if vec.sum() <= 0:\n",
    "        return np.zeros_like(vec)\n",
    "    return vec / vec.sum()\n",
    "\n",
    "# --- Context ì•ˆì „ ì ‘ê·¼ ìœ í‹¸ ---\n",
    "def ctx_pick(ctx, keys, default=None):\n",
    "    \"\"\"\n",
    "    ctxê°€ dictì¼ ìˆ˜ë„, ê°ì²´ì¼ ìˆ˜ë„ ìˆìœ¼ë¯€ë¡œ\n",
    "    keys(ìš°ì„ ìˆœìœ„ ë¦¬ìŠ¤íŠ¸)ë¥¼ ìˆœì„œëŒ€ë¡œ íƒìƒ‰í•´ì„œ ì²« ë§¤ì¹­ ê°’ì„ ë°˜í™˜.\n",
    "    \"\"\"\n",
    "    if ctx is None:\n",
    "        return default\n",
    "    for k in keys:\n",
    "        # dict\n",
    "        if isinstance(ctx, dict) and k in ctx:\n",
    "            return ctx[k]\n",
    "        # ê°ì²´ ì†ì„±\n",
    "        if hasattr(ctx, k):\n",
    "            return getattr(ctx, k)\n",
    "    return default\n",
    "\n",
    "# --- ë¯¹ìŠ¤ ì˜ì¡´í˜• ë³´ìƒ í•¨ìˆ˜ (ctx ê°ì²´ ëŒ€ì‘ìœ¼ë¡œ ìˆ˜ì •) ---\n",
    "def compute_metrics_mix_dependent(grains_df, mix, ctx=None):\n",
    "    w = _mix_vector(mix, grains_df)\n",
    "\n",
    "    gi      = np.dot(w, _col(grains_df, \"gi\", default=55))\n",
    "    fiber   = np.dot(w, _col(grains_df, \"fiber\", default=0.0))\n",
    "    protein = np.dot(w, _col(grains_df, \"protein\", default=0.0))\n",
    "    soft    = np.dot(w, _col(grains_df, \"soft\", default=0.0))\n",
    "    sticky  = np.dot(w, _col(grains_df, \"sticky\", default=0.0))\n",
    "    nutty   = np.dot(w, _col(grains_df, \"nutty\", default=0.0))\n",
    "    gluten  = np.dot(w, _col(grains_df, \"gluten\", default=0.0))\n",
    "\n",
    "    # ëª©ì  ê°€ì¤‘ì¹˜\n",
    "    wp = {\n",
    "        \"í˜ˆë‹¹ê´€ë¦¬\":           dict(gi=1.2, fiber=1.0, protein=0.4),\n",
    "        \"ì²´ì¤‘ ê´€ë¦¬\":          dict(gi=0.9, fiber=1.1, protein=0.6),\n",
    "        \"ê·¼ìœ¡ ë° ì—ë„ˆì§€ ë³´ê°•\": dict(gi=0.4, fiber=0.6, protein=1.2),\n",
    "        \"ì‹¬í˜ˆê´€ ê±´ê°•\":        dict(gi=0.6, fiber=1.1, protein=0.6),\n",
    "        \"ì¥ ê±´ê°•\":            dict(gi=0.4, fiber=1.2, protein=0.4),\n",
    "        \"ë§›ì¤‘ì‹¬\":             dict(gi=0.5, fiber=0.5, protein=0.5),\n",
    "    }\n",
    "    # âœ… dict/ê°ì²´ ëª¨ë‘ ì§€ì›\n",
    "    obj = ctx_pick(ctx, [\"purpose\", \"ì·¨ì‹ ëª©ì \", \"ëª©ì \"], default=\"ë§›ì¤‘ì‹¬\")\n",
    "    pw = wp.get(obj, wp[\"ë§›ì¤‘ì‹¬\"])\n",
    "\n",
    "    # ì‹ê° ì„ í˜¸ ë°˜ì˜ (dict/ê°ì²´ ëª¨ë‘ ì§€ì›)\n",
    "    taste_pref = ctx_pick(ctx, [\"taste_pref\", \"ì„ í˜¸ì‹ê°/ë§›\", \"ì‹ê°\"], default=None)\n",
    "    if taste_pref == \"ê³ ìŠ¬ë°¥\":\n",
    "        taste_term = 0.6*soft + 0.2*sticky\n",
    "    elif taste_pref == \"ì°°ì§„ë°¥\":\n",
    "        taste_term = 0.6*sticky + 0.2*soft\n",
    "    else:\n",
    "        taste_term = 0.4*soft + 0.4*sticky\n",
    "\n",
    "    reward = (\n",
    "        - pw[\"gi\"]      * gi/100.0 +\n",
    "          pw[\"fiber\"]   * fiber/10.0 +\n",
    "          pw[\"protein\"] * protein/10.0 +\n",
    "        + 0.3           * taste_term +\n",
    "        - 0.5           * gluten\n",
    "    )\n",
    "\n",
    "    return {\n",
    "        \"gi\": float(gi), \"fiber\": float(fiber), \"protein\": float(protein),\n",
    "        \"soft\": float(soft), \"sticky\": float(sticky), \"nutty\": float(nutty),\n",
    "        \"gluten\": float(gluten),\n",
    "        \"reward\": float(reward),\n",
    "    }\n",
    "\n",
    "\n",
    "# âš ï¸ ì´ ì…€ ì´í›„ì—ëŠ” compute_metrics(...)ê°€ â€œë°°í•© ì˜ì¡´í˜• + reward í¬í•¨â€ìœ¼ë¡œ ë™ì‘í•˜ë„ë¡ ë˜í•‘\n",
    "def compute_metrics(grains_df, mix, ctx=None):\n",
    "    return compute_metrics_mix_dependent(grains_df, mix, ctx)\n",
    "\n",
    "# === í†µì¼ íŒ¨ì¹˜(ëª½í‚¤ íŒ¨ì¹˜): í•™ìŠµê³¼ í‰ê°€ê°€ ê°™ì€ ë³´ìƒì‹/ì§€í‘œë¥¼ ì“°ë„ë¡ ê°•ì œ\n",
    "import agent_core, agent_adapter\n",
    "\n",
    "def unified_compute_metrics(grains_df, mix, ctx=None):\n",
    "    return compute_metrics_mix_dependent(grains_df, mix, ctx)\n",
    "\n",
    "def unified_reward(grains_df, mix, ctx):\n",
    "    return unified_compute_metrics(grains_df, mix, ctx)[\"reward\"]\n",
    "\n",
    "agent_core.compute_metrics = unified_compute_metrics\n",
    "agent_core.reward = unified_reward\n",
    "agent_adapter.compute_metrics = unified_compute_metrics  # (ì•ˆì „ìš©)\n",
    "\n",
    "# ì„ íƒ: ì œëŒ€ë¡œ íŒ¨ì¹˜ëëŠ”ì§€ í™•ì¸\n",
    "print(\"agent_core.compute_metrics ->\", agent_core.compute_metrics.__name__)\n",
    "print(\"agent_core.reward ->\", agent_core.reward.__name__)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc49ae5c",
   "metadata": {},
   "source": [
    "## 5) Pairwise ë°ì´í„° ìƒì„± â†’ ë­ì»¤ í•™ìŠµ/í‰ê°€"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X shape: (960000, 14) | y: (960000,)\n",
      "AUC(train): 0.5913596263802083\n"
     ]
    }
   ],
   "source": [
    "from agent_adapter import make_pairwise_dataset_from_surveys\n",
    "import numpy as np\n",
    "\n",
    "N_PAIRS    = 8    # ì„¤ë¬¸ë‹¹ pair ìˆ˜ (ë°ì´í„°ëŸ‰/ì‹œê°„ ì¡°ì ˆ)\n",
    "RAND_SCALE = 8.0  # í›„ë³´ ë‹¤ì–‘ì„±\n",
    "\n",
    "grains_df, X, y = make_pairwise_dataset_from_surveys(\n",
    "    subset,\n",
    "    n_pairs_per_survey=N_PAIRS,\n",
    "    rand_scale=RAND_SCALE,\n",
    "    seed=42\n",
    ")\n",
    "X = X.astype(float); y = y.astype(int)\n",
    "print(\"X shape:\", X.shape, \"| y:\", y.shape)\n",
    "\n",
    "from agent_core import Ranker\n",
    "ranker = Ranker().fit(X, y)\n",
    "print(\"AUC(train):\", ranker.score(X, y))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6) ì¶”ë¡  ë°ëª¨ (ë£° Râ‚€ vs ì—ì´ì „íŠ¸)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[í…ŒìŠ¤íŠ¸ ì„¤ë¬¸] {'ì·¨ì‹ ëª©ì ': 'ì¥ ê±´ê°•', 'í˜„ì¬ ê±´ê°• ì´ìŠˆ': 'ì„ì‹ /ìˆ˜ìœ ', 'ë‚˜ì´': '50ëŒ€ ì´ìƒ', 'ì„±ë³„': 'ì—¬', 'ì„ í˜¸ì‹ê°/ë§›': 'ê³ ìŠ¬ë°¥', 'ì„­ì·¨ ë¹ˆë„': 'ë§¤ì¼', 'ê³¡ë¬¼ ìˆ˜': 5, 'ê¸°í”¼ê³¡ë¬¼': ['ìœ¨ë¬´', 'í€´ë…¸ì•„'], 'ì•Œë ˆë¥´ê² íšŒí”¼(ê¸€ë£¨í…)': False, 'ì²´ì§ˆ': 'ë³´í†µ', 'ì¥ê±´ê°•': 'ë³´í†µ', 'ë§›': 'ë‹´ë°±/ì¤‘ì„±'}\n",
      "\n",
      "[ë£° ë°°í•© R0] {'ë Œí‹¸ì½©': np.float64(15.0), 'ê·€ë¦¬': np.float64(15.0), 'ê¸°ì¥': np.float64(15.0), 'ì„œë¦¬íƒœ': np.float64(15.0), 'ë°±ë¯¸': np.float64(40.0)}\n",
      "\n",
      "[ì—ì´ì „íŠ¸ ì¶”ì²œ ë°°í•©] {'ë Œí‹¸ì½©': np.float64(15.0), 'ê·€ë¦¬': np.float64(15.0), 'ê¸°ì¥': np.float64(18.85375485573114), 'ì„œë¦¬íƒœ': np.float64(15.0), 'ë°±ë¯¸': np.float64(36.14624514426886)}\n",
      "\n",
      "[ì§€í‘œ R0] {'gi': 2.1, 'fiber': 1.3499999999999999, 'protein': 1.3499999999999999, 'soft': 1.95, 'sticky': 0.6, 'nutty': 0.9, 'gluten': 0.0, 'reward': 0.4305}\n",
      "[ì§€í‘œ Best] {'gi': 2.0614624514426887, 'fiber': 1.3885375485573113, 'protein': 1.3885375485573113, 'soft': 1.9114624514426886, 'sticky': 0.6385375485573114, 'nutty': 0.9385375485573114, 'gluten': 0.0, 'reward': 0.43454644259851766}\n",
      "Î” reward: 0.004\n"
     ]
    }
   ],
   "source": [
    "from agent_adapter import map_survey_to_context, rule_recommend_from_rules_core\n",
    "from agent_core import project_constraints\n",
    "import random\n",
    "\n",
    "test_survey = random.choice(subset)  # âœ… í•™ìŠµ ë¶„í¬ì™€ ì¼ì¹˜\n",
    "ctx = map_survey_to_context(test_survey)\n",
    "\n",
    "r0 = rule_recommend_from_rules_core(ctx, grains_df)\n",
    "best = ranker.infer_best(grains_df, ctx, rule_recommend_from_rules_core,\n",
    "                         n_candidates=12, rand_scale=6.0)\n",
    "best = project_constraints(best, grains_df, ctx)\n",
    "\n",
    "print(\"[í…ŒìŠ¤íŠ¸ ì„¤ë¬¸]\", test_survey)\n",
    "print(\"\\n[ë£° ë°°í•© R0]\", r0)\n",
    "print(\"\\n[ì—ì´ì „íŠ¸ ì¶”ì²œ ë°°í•©]\", best)\n",
    "\n",
    "m0 = compute_metrics(grains_df, r0, ctx)     # âœ… ctx ì „ë‹¬\n",
    "m1 = compute_metrics(grains_df, best, ctx)   # âœ… ctx ì „ë‹¬\n",
    "print(\"\\n[ì§€í‘œ R0]\", m0)\n",
    "print(\"[ì§€í‘œ Best]\", m1)\n",
    "print(\"Î” reward:\", round(m1[\"reward\"] - m0[\"reward\"], 4))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c635ad5",
   "metadata": {},
   "source": [
    "## 7) í›„ë³´ ë‹¤ì–‘ì„±/íˆ¬ì˜ ì ê²€ (ì„ íƒ)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "75ff0d62",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "unique candidates: 12\n",
      "unique after project: 12\n"
     ]
    }
   ],
   "source": [
    "from copy import deepcopy\n",
    "\n",
    "def probe_candidates(grains_df, ctx, n_candidates=12, rand_scale=6.0):\n",
    "    base = rule_recommend_from_rules_core(ctx, grains_df)\n",
    "    cands = [base]\n",
    "    for _ in range(n_candidates-1):\n",
    "        cand = deepcopy(base)\n",
    "        import random\n",
    "        keys = list(cand.keys())\n",
    "        a, b = random.sample(keys, 2)\n",
    "        delta = random.uniform(-rand_scale, rand_scale)\n",
    "        cand[a] = max(0, cand[a] + delta)\n",
    "        cand[b] = max(0, cand[b] - delta)\n",
    "        s = sum(cand.values())\n",
    "        if s > 0:\n",
    "            for k in cand: cand[k] = cand[k] * 100.0 / s\n",
    "        cands.append(cand)\n",
    "    return cands\n",
    "\n",
    "cands = probe_candidates(grains_df, ctx, n_candidates=12, rand_scale=6.0)\n",
    "print(\"unique candidates:\", len({tuple(sorted(d.items())) for d in cands}))\n",
    "\n",
    "proj = [project_constraints(c, grains_df, ctx) for c in cands]\n",
    "print(\"unique after project:\", len({tuple(sorted(d.items())) for d in proj}))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d497dc53",
   "metadata": {},
   "source": [
    "## 8) A/B ë¦¬í¬íŠ¸ (ì•ˆì „ ë²„ì „)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "2b200f97",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[A/B] N=100\n",
      "- R0 mean reward:   0.4034\n",
      "- Best mean reward: 0.4130\n",
      "- Win rate (Best > R0): 100.0%\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "from statistics import mean\n",
    "\n",
    "def ab_report(grains_df, ranker, surveys, n=100, n_candidates=12, rand_scale=6.0):\n",
    "    wins = 0\n",
    "    r0_rewards, best_rewards = [], []\n",
    "    for _ in range(n):\n",
    "        s = random.choice(surveys)\n",
    "        ctx = map_survey_to_context(s)\n",
    "        r0 = rule_recommend_from_rules_core(ctx, grains_df)\n",
    "        best = ranker.infer_best(grains_df, ctx, rule_recommend_from_rules_core,\n",
    "                                 n_candidates=n_candidates, rand_scale=rand_scale)\n",
    "        best = project_constraints(best, grains_df, ctx)\n",
    "\n",
    "        r0_reward   = compute_metrics(grains_df, r0, ctx)[\"reward\"]     # âœ… ctx ì „ë‹¬\n",
    "        best_reward = compute_metrics(grains_df, best, ctx)[\"reward\"]   # âœ… ctx ì „ë‹¬\n",
    "\n",
    "        r0_rewards.append(r0_reward)\n",
    "        best_rewards.append(best_reward)\n",
    "        wins += (best_reward > r0_reward)\n",
    "\n",
    "    print(f\"[A/B] N={n}\")\n",
    "    print(f\"- R0 mean reward:   {mean(r0_rewards):.4f}\")\n",
    "    print(f\"- Best mean reward: {mean(best_rewards):.4f}\")\n",
    "    print(f\"- Win rate (Best > R0): {wins/n:.1%}\")\n",
    "\n",
    "ab_report(grains_df, ranker, subset, n=100, n_candidates=12, rand_scale=6.0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9edfbf5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
